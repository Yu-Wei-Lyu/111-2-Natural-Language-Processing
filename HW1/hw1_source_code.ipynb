{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1hsNtj9NiKWLlG1OIzlCNocYFTj4f5x8-","authorship_tag":"ABX9TyOUrm2YSXzUbDedzihOjN1E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","# 讀取training & test 資料\n","train_data = pd.read_csv(\"https://raw.githubusercontent.com/cblancac/SentimentAnalysisBert/main/data/train_150k.txt\", sep=\"\\t\", names=[\"feeling\", \"text\"])\n","test_data = pd.read_csv(\"https://raw.githubusercontent.com/cblancac/SentimentAnalysisBert/main/data/test_62k.txt\", sep=\"\\t\", names=[\"feeling\", \"text\"])\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import string\n","# 資料雜質過濾\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","stop_words = set(stopwords.words(\"english\"))\n","negation_list = [\"not\", \"no\", \"never\"]\n","def preprocess_text(text):\n","    # 全部小寫\n","    text = text.lower()\n","    # 去除標點符號\n","    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n","    # 分詞\n","    words = word_tokenize(text)\n","    # 去除無相關字\n","    words = [w for w in words if not w in stop_words]\n","    # 否定語法代換\n","    new_words = []\n","    negation = False\n","    for word in words:\n","        if word in negation_list:\n","            negation = True\n","        elif negation:\n","            word = \"not_\" + word\n","            negation = False\n","        new_words.append(word)\n","    return \" \".join(words)\n","train_data[\"text\"] = train_data[\"text\"].apply(preprocess_text)\n","test_data[\"text\"] = test_data[\"text\"].apply(preprocess_text)\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","# 將資料轉為詞袋\n","vectorizer = CountVectorizer()\n","X_train = vectorizer.fit_transform(train_data[\"text\"])\n","X_test = vectorizer.transform(test_data[\"text\"])\n","\n","from sklearn.linear_model import LogisticRegression\n","# 創建並訓練邏輯迴歸分類器 (Logistic Regression)\n","lr = LogisticRegression(max_iter=500)\n","lr.fit(X_train, train_data[\"feeling\"])\n","y_pred_lr = lr.predict(X_test)\n","print(\"Logistic Regression Accuracy:\", accuracy_score(test_data[\"feeling\"], y_pred_lr))\n","\n","from sklearn.naive_bayes import MultinomialNB\n","# 創建貝氏分類器\n","nb = MultinomialNB()\n","# 定義需要嘗試的貝氏alpha值\n","param_grid = {\"alpha\":  [2.066, 2.067, 2.068]}\n","from sklearn.model_selection import GridSearchCV\n","# 使用網格搜索最佳貝氏alpha值\n","grid_search = GridSearchCV(nb, param_grid, cv=5)\n","grid_search.fit(X_train, train_data[\"feeling\"])\n","# 输出最佳貝氏alpha值 \n","#print(grid_search.best_params_) #2.067\n","\n","# 創建並訓練貝氏分類並使用最佳貝氏alpha值\n","nb_best = MultinomialNB(alpha=2.067)\n","nb_best.fit(X_train, train_data[\"feeling\"])\n","y_pred_nb = nb_best.predict(X_test)\n","print(\"Naive Bayes Accuracy:\", accuracy_score(test_data[\"feeling\"], y_pred_nb))\n","\n","from sklearn.ensemble import VotingClassifier\n","# 創建並結合貝式與邏輯分類器的投票分類器\n","voting_clf = VotingClassifier(estimators=[(\"lr\", lr), (\"nb\", nb_best)], voting=\"soft\")\n","# 訓練投票分類器\n","voting_clf.fit(X_train, train_data[\"feeling\"])\n","y_pred_voting = voting_clf.predict(X_test)\n","print(\"Voting Classifier Accuracy:\", accuracy_score(test_data[\"feeling\"], y_pred_voting))\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","#輸出模型參考值\n","print(\"Precision:\", precision_score(test_data[\"feeling\"], y_pred_voting, average=\"macro\"))\n","print(\"Recall:\", recall_score(test_data[\"feeling\"], y_pred_voting, average=\"macro\"))\n","print(\"F measure:\", f1_score(test_data[\"feeling\"], y_pred_voting, average=\"macro\"))\n","print(\"Accuracy:\", accuracy_score(test_data[\"feeling\"], y_pred_voting))\n","\n","#輸出分類檔\n","classification_output = [(str(y_pred_voting[i]) + ' ' + str(test_data[\"text\"][i]) + '\\n') for i in range(len(y_pred_voting))]\n","fp = open(\"/content/drive/MyDrive/My Drive/Colab Notebooks/自然語言處理與文件探勘/test_output.txt\", \"w\")\n","fp.writelines(classification_output)\n","fp.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vaNu171w4ob","outputId":"6043660b-ed3e-4dd5-ef5f-555ff1e4525c","executionInfo":{"status":"ok","timestamp":1679920646110,"user_tz":-480,"elapsed":88354,"user":{"displayName":"YellowDuck","userId":"10048978787730505253"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy: 0.7674763702054905\n","Naive Bayes Accuracy: 0.7590244846607955\n","Voting Classifier Accuracy: 0.7686215684376916\n","Precision: 0.7691114352180215\n","Recall: 0.7686420346673658\n","F measure: 0.7685252012008035\n","Accuracy: 0.7686215684376916\n"]}]}]}