{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ef6a20",
   "metadata": {},
   "source": [
    "## 1. 先提取需要的套件和製作提取資料的 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9229609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2afed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll_file(file_name):\n",
    "    current_item = []\n",
    "    current_words = []\n",
    "    current_tag_classes = []\n",
    "    with open(file_name, encoding='utf-8') as conll:\n",
    "        for line in conll:\n",
    "            line = line.strip()\n",
    "            if line and len(line.split()) == 2: # 排除空行和參數不完整的行\n",
    "                word, tag_class = line.split()\n",
    "                current_item.append((word, tag_class))\n",
    "                current_words.append(word)\n",
    "                current_tag_classes.append(tag_class)\n",
    "    return current_item\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3723d89",
   "metadata": {},
   "source": [
    "## 2. 提取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d012687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=[(word_feats(words), tag_classes) for (words, tag_classes) in read_conll_file('e.conll')]\n",
    "test_set=[(word_feats(words), tag_classes) for (words, tag_classes) in read_conll_file('f.conll')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee4306",
   "metadata": {},
   "source": [
    "## 3. 使用Bayes分類器進行訓練，再進行預測並取得結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2aac71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "test_predict = []\n",
    "testing = []\n",
    "for item in test_set:\n",
    "    test_predict.append(classifier.classify(item[0]))\n",
    "    testing.append(item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb43ee7a",
   "metadata": {},
   "source": [
    "## 4.使用Bayes分類器進行訓練、再進行預測並取得結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12ed2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision： [0.0872056  0.2125576  0.27983539 0.01388889 0.01173709 0.00884956\n",
      " 0.92682038]\n",
      "Recall： [0.21540881 0.33853211 0.02566038 0.00480769 0.06097561 0.01115242\n",
      " 0.92254171]\n",
      "F1-score： [0.12415043 0.2611465  0.04701002 0.00714286 0.01968504 0.00986842\n",
      " 0.9246761 ]\n",
      "Accuracy： 0.8064925899788286\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(testing, test_predict, average=None)\n",
    "recall = recall_score(testing, test_predict, average=None)\n",
    "f1 = f1_score(testing, test_predict, average=None)\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "\n",
    "print(f'Precision： {precision}')\n",
    "print(f'Recall： {recall}')\n",
    "print(f'F1-score： {f1}')\n",
    "print(f'Accuracy： {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5994be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
